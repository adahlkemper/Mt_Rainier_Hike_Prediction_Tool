{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "133a9cb2",
   "metadata": {},
   "source": [
    "# Mt. Rainier Hike Prediction Tool - Logistic Regression & SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0a80b9",
   "metadata": {},
   "source": [
    "Mt. Rainier hikes are an incredibly popular adventure with outdoor enthusiasts, as Mount Rainier National Park is the gem of Washington State. Right now I am trying to develop a feature in a smartphone app, which, based on weather and other relevant data recorded for Mt Rainer National park on a given day, can predict and notify an app user if they should climb it or not on that day.\n",
    "\n",
    "Input: A set of weather related and other attributes for a given day for Mt. Rainer.\n",
    "\n",
    "Output: User should climb Mt. Rainer (class 1) or not on that day (class 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a51d1",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1927a238",
   "metadata": {},
   "source": [
    "The dataset is sourced from https://www.kaggle.com/datasets/codersree/mount-rainier-weather-and-climbing-data. It matches the weather report to climbing data from the period of 2014 to 2015. The data contains Date, the various weather parameters averaged daily (Temperature, Battery Voltage, Relative Humidity, Wind Speed, Wind Direction, Solare Radision), the climbing statistics and the target the success percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d9db12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data (1895, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Route</th>\n",
       "      <th>Succeeded</th>\n",
       "      <th>Battery Voltage AVG</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11/27/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.643750</td>\n",
       "      <td>26.321667</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>27.839583</td>\n",
       "      <td>68.004167</td>\n",
       "      <td>88.496250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11/21/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.749583</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>21.690708</td>\n",
       "      <td>2.245833</td>\n",
       "      <td>117.549667</td>\n",
       "      <td>93.660417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10/15/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.461250</td>\n",
       "      <td>46.447917</td>\n",
       "      <td>27.211250</td>\n",
       "      <td>17.163625</td>\n",
       "      <td>259.121375</td>\n",
       "      <td>138.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10/13/2015</td>\n",
       "      <td>Little Tahoma</td>\n",
       "      <td>0</td>\n",
       "      <td>13.532083</td>\n",
       "      <td>40.979583</td>\n",
       "      <td>28.335708</td>\n",
       "      <td>19.591167</td>\n",
       "      <td>279.779167</td>\n",
       "      <td>176.382667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10/9/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.216250</td>\n",
       "      <td>38.260417</td>\n",
       "      <td>74.329167</td>\n",
       "      <td>65.138333</td>\n",
       "      <td>264.687500</td>\n",
       "      <td>27.791292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date                   Route  Succeeded  \\\n",
       "0           0  11/27/2015  Disappointment Cleaver          0   \n",
       "1           1  11/21/2015  Disappointment Cleaver          0   \n",
       "2           2  10/15/2015  Disappointment Cleaver          0   \n",
       "3           3  10/13/2015           Little Tahoma          0   \n",
       "4           4   10/9/2015  Disappointment Cleaver          0   \n",
       "\n",
       "   Battery Voltage AVG  Temperature AVG  Relative Humidity AVG  \\\n",
       "0            13.643750        26.321667              19.715000   \n",
       "1            13.749583        31.300000              21.690708   \n",
       "2            13.461250        46.447917              27.211250   \n",
       "3            13.532083        40.979583              28.335708   \n",
       "4            13.216250        38.260417              74.329167   \n",
       "\n",
       "   Wind Speed Daily AVG  Wind Direction AVG  Solare Radiation AVG  \n",
       "0             27.839583           68.004167             88.496250  \n",
       "1              2.245833          117.549667             93.660417  \n",
       "2             17.163625          259.121375            138.387000  \n",
       "3             19.591167          279.779167            176.382667  \n",
       "4             65.138333          264.687500             27.791292  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import relavant software\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "#Import File\n",
    "ranier_df = pd.read_csv(\"/Users/audreydahlkemper/Downloads/MtRainier_data (1).csv\")\n",
    "ranier_df = ranier_df.drop_duplicates()\n",
    "\n",
    "\n",
    "# Apply dropna() to get rid of duplicates\n",
    "ranier_df = ranier_df.dropna()\n",
    "print (f\"Shape of data {ranier_df.shape}\")\n",
    "ranier_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94eb630c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1895 entries, 0 to 1894\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             1895 non-null   int64  \n",
      " 1   Date                   1895 non-null   object \n",
      " 2   Route                  1895 non-null   object \n",
      " 3   Succeeded              1895 non-null   int64  \n",
      " 4   Battery Voltage AVG    1895 non-null   float64\n",
      " 5   Temperature AVG        1895 non-null   float64\n",
      " 6   Relative Humidity AVG  1895 non-null   float64\n",
      " 7   Wind Speed Daily AVG   1895 non-null   float64\n",
      " 8   Wind Direction AVG     1895 non-null   float64\n",
      " 9   Solare Radiation AVG   1895 non-null   float64\n",
      "dtypes: float64(6), int64(2), object(2)\n",
      "memory usage: 162.9+ KB\n"
     ]
    }
   ],
   "source": [
    "ranier_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b30911",
   "metadata": {},
   "source": [
    "The features Route and Date are categorical. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93580d38",
   "metadata": {},
   "source": [
    "### 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1acbe80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Route</th>\n",
       "      <th>Battery Voltage AVG</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/27/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>13.643750</td>\n",
       "      <td>26.321667</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>27.839583</td>\n",
       "      <td>68.004167</td>\n",
       "      <td>88.496250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/21/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>13.749583</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>21.690708</td>\n",
       "      <td>2.245833</td>\n",
       "      <td>117.549667</td>\n",
       "      <td>93.660417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/15/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>13.461250</td>\n",
       "      <td>46.447917</td>\n",
       "      <td>27.211250</td>\n",
       "      <td>17.163625</td>\n",
       "      <td>259.121375</td>\n",
       "      <td>138.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/13/2015</td>\n",
       "      <td>Little Tahoma</td>\n",
       "      <td>13.532083</td>\n",
       "      <td>40.979583</td>\n",
       "      <td>28.335708</td>\n",
       "      <td>19.591167</td>\n",
       "      <td>279.779167</td>\n",
       "      <td>176.382667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/9/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>13.216250</td>\n",
       "      <td>38.260417</td>\n",
       "      <td>74.329167</td>\n",
       "      <td>65.138333</td>\n",
       "      <td>264.687500</td>\n",
       "      <td>27.791292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                   Route  Battery Voltage AVG  Temperature AVG  \\\n",
       "0  11/27/2015  Disappointment Cleaver            13.643750        26.321667   \n",
       "1  11/21/2015  Disappointment Cleaver            13.749583        31.300000   \n",
       "2  10/15/2015  Disappointment Cleaver            13.461250        46.447917   \n",
       "3  10/13/2015           Little Tahoma            13.532083        40.979583   \n",
       "4   10/9/2015  Disappointment Cleaver            13.216250        38.260417   \n",
       "\n",
       "   Relative Humidity AVG  Wind Speed Daily AVG  Wind Direction AVG  \\\n",
       "0              19.715000             27.839583           68.004167   \n",
       "1              21.690708              2.245833          117.549667   \n",
       "2              27.211250             17.163625          259.121375   \n",
       "3              28.335708             19.591167          279.779167   \n",
       "4              74.329167             65.138333          264.687500   \n",
       "\n",
       "   Solare Radiation AVG  \n",
       "0             88.496250  \n",
       "1             93.660417  \n",
       "2            138.387000  \n",
       "3            176.382667  \n",
       "4             27.791292  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Succeeded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Succeeded\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframes for features and labels\n",
    "ranier_features_df = ranier_df[[\"Date\", \"Route\", \"Battery Voltage AVG\", \"Temperature AVG\", \"Relative Humidity AVG\", \"Wind Speed Daily AVG\", \"Wind Direction AVG\", \"Solare Radiation AVG\"]]\n",
    "ranier_labels_df = ranier_df[[\"Succeeded\"]]\n",
    "\n",
    "ranier_features_df.head()\n",
    "ranier_labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e57f0",
   "metadata": {},
   "source": [
    "Transform the first categorical variable, Route, into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93261f69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique vocabulary items 22\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Battery Voltage AVG</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/27/2015</td>\n",
       "      <td>13.643750</td>\n",
       "      <td>26.321667</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>27.839583</td>\n",
       "      <td>68.004167</td>\n",
       "      <td>88.496250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/21/2015</td>\n",
       "      <td>13.749583</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>21.690708</td>\n",
       "      <td>2.245833</td>\n",
       "      <td>117.549667</td>\n",
       "      <td>93.660417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/15/2015</td>\n",
       "      <td>13.461250</td>\n",
       "      <td>46.447917</td>\n",
       "      <td>27.211250</td>\n",
       "      <td>17.163625</td>\n",
       "      <td>259.121375</td>\n",
       "      <td>138.387000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/13/2015</td>\n",
       "      <td>13.532083</td>\n",
       "      <td>40.979583</td>\n",
       "      <td>28.335708</td>\n",
       "      <td>19.591167</td>\n",
       "      <td>279.779167</td>\n",
       "      <td>176.382667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/9/2015</td>\n",
       "      <td>13.216250</td>\n",
       "      <td>38.260417</td>\n",
       "      <td>74.329167</td>\n",
       "      <td>65.138333</td>\n",
       "      <td>264.687500</td>\n",
       "      <td>27.791292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Battery Voltage AVG  Temperature AVG  Relative Humidity AVG  \\\n",
       "0  11/27/2015            13.643750        26.321667              19.715000   \n",
       "1  11/21/2015            13.749583        31.300000              21.690708   \n",
       "2  10/15/2015            13.461250        46.447917              27.211250   \n",
       "3  10/13/2015            13.532083        40.979583              28.335708   \n",
       "4   10/9/2015            13.216250        38.260417              74.329167   \n",
       "\n",
       "   Wind Speed Daily AVG  Wind Direction AVG  Solare Radiation AVG    0    1  \\\n",
       "0             27.839583           68.004167             88.496250  0.0  1.0   \n",
       "1              2.245833          117.549667             93.660417  0.0  1.0   \n",
       "2             17.163625          259.121375            138.387000  0.0  1.0   \n",
       "3             19.591167          279.779167            176.382667  0.0  0.0   \n",
       "4             65.138333          264.687500             27.791292  0.0  1.0   \n",
       "\n",
       "     2  ...   12   13   14   15   16   17   18   19   20   21  \n",
       "0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Transform categorical features into 1-hot\n",
    "route_to_list = ranier_features_df[\"Route\"].to_list()\n",
    "route_to_list_of_lists = []\n",
    "\n",
    "for name in route_to_list:\n",
    "    route_to_list_of_lists.append([name])\n",
    "    \n",
    "route_encoder = OneHotEncoder()\n",
    "route_encoder.fit(route_to_list_of_lists)\n",
    "\n",
    "print(f\"Unique vocabulary items {len(route_encoder.categories_[0])}\\n\")\n",
    "\n",
    "route_transformed = route_encoder.transform(route_to_list_of_lists)\n",
    "route_transformed = route_transformed.toarray()\n",
    "route_transformed_df = pd.DataFrame(route_transformed)\n",
    "\n",
    "ranier_features_df.reset_index(drop=True, inplace=True)\n",
    "route_transformed_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ranier_features_transformed_df = pd.concat([ranier_features_df,route_transformed_df], axis=1)\n",
    "ranier_features_transformed_df = ranier_features_transformed_df.drop(columns=[\"Route\"], axis=1)\n",
    "ranier_features_df = ranier_features_transformed_df\n",
    "ranier_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0178f",
   "metadata": {},
   "source": [
    "Transform the first categorical variable, Date, into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f1dfe79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique vocabulary items 204\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Battery Voltage AVG</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.643750</td>\n",
       "      <td>26.321667</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>27.839583</td>\n",
       "      <td>68.004167</td>\n",
       "      <td>88.496250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.749583</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>21.690708</td>\n",
       "      <td>2.245833</td>\n",
       "      <td>117.549667</td>\n",
       "      <td>93.660417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.461250</td>\n",
       "      <td>46.447917</td>\n",
       "      <td>27.211250</td>\n",
       "      <td>17.163625</td>\n",
       "      <td>259.121375</td>\n",
       "      <td>138.387000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.532083</td>\n",
       "      <td>40.979583</td>\n",
       "      <td>28.335708</td>\n",
       "      <td>19.591167</td>\n",
       "      <td>279.779167</td>\n",
       "      <td>176.382667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.216250</td>\n",
       "      <td>38.260417</td>\n",
       "      <td>74.329167</td>\n",
       "      <td>65.138333</td>\n",
       "      <td>264.687500</td>\n",
       "      <td>27.791292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Battery Voltage AVG  Temperature AVG  Relative Humidity AVG  \\\n",
       "0            13.643750        26.321667              19.715000   \n",
       "1            13.749583        31.300000              21.690708   \n",
       "2            13.461250        46.447917              27.211250   \n",
       "3            13.532083        40.979583              28.335708   \n",
       "4            13.216250        38.260417              74.329167   \n",
       "\n",
       "   Wind Speed Daily AVG  Wind Direction AVG  Solare Radiation AVG    0    1  \\\n",
       "0             27.839583           68.004167             88.496250  0.0  1.0   \n",
       "1              2.245833          117.549667             93.660417  0.0  1.0   \n",
       "2             17.163625          259.121375            138.387000  0.0  1.0   \n",
       "3             19.591167          279.779167            176.382667  0.0  0.0   \n",
       "4             65.138333          264.687500             27.791292  0.0  1.0   \n",
       "\n",
       "     2    3  ...  194  195  196  197  198  199  200  201  202  203  \n",
       "0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 232 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_to_list = ranier_features_df[\"Date\"].to_list()\n",
    "date_to_list_of_lists = []\n",
    "\n",
    "for name in date_to_list:\n",
    "    date_to_list_of_lists.append([name])\n",
    "    \n",
    "date_encoder = OneHotEncoder()\n",
    "date_encoder.fit(date_to_list_of_lists)\n",
    "\n",
    "print(f\"Unique vocabulary items {len(date_encoder.categories_[0])}\\n\")\n",
    "\n",
    "date_transformed = date_encoder.transform(date_to_list_of_lists)\n",
    "date_transformed = date_transformed.toarray()\n",
    "date_transformed_df = pd.DataFrame(date_transformed)\n",
    "\n",
    "ranier_features_df.reset_index(drop=True, inplace=True)\n",
    "date_transformed_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ranier_features_transformed_df = pd.concat([ranier_features_df,date_transformed_df], axis=1)\n",
    "ranier_features_transformed_df = ranier_features_transformed_df.drop(columns=[\"Date\"], axis=1)\n",
    "ranier_features_df = ranier_features_transformed_df\n",
    "ranier_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc9769f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1895 entries, 0 to 1894\n",
      "Columns: 232 entries, Battery Voltage AVG to 203\n",
      "dtypes: float64(232)\n",
      "memory usage: 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "ranier_features_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1b252",
   "metadata": {},
   "source": [
    "### 3. Scale the Data Using Standard Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f03b3f",
   "metadata": {},
   "source": [
    "Scale the data using Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbbf8eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/audreydahlkemper/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/audreydahlkemper/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Battery Voltage AVG</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.003522</td>\n",
       "      <td>-1.580891</td>\n",
       "      <td>-1.269311</td>\n",
       "      <td>1.895222</td>\n",
       "      <td>-0.958813</td>\n",
       "      <td>-1.567664</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>0.681507</td>\n",
       "      <td>-0.429389</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.072836</td>\n",
       "      <td>-0.03982</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.03982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.506158</td>\n",
       "      <td>-1.033951</td>\n",
       "      <td>-1.180109</td>\n",
       "      <td>-0.902775</td>\n",
       "      <td>-0.414849</td>\n",
       "      <td>-1.520897</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>0.681507</td>\n",
       "      <td>-0.429389</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.072836</td>\n",
       "      <td>-0.03982</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.03982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.587638</td>\n",
       "      <td>0.630261</td>\n",
       "      <td>-0.930861</td>\n",
       "      <td>0.728090</td>\n",
       "      <td>1.139477</td>\n",
       "      <td>-1.115850</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>0.681507</td>\n",
       "      <td>-0.429389</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.072836</td>\n",
       "      <td>-0.03982</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.03982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.418063</td>\n",
       "      <td>0.029488</td>\n",
       "      <td>-0.880092</td>\n",
       "      <td>0.993477</td>\n",
       "      <td>1.366280</td>\n",
       "      <td>-0.771758</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>-1.467337</td>\n",
       "      <td>-0.429389</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.072836</td>\n",
       "      <td>-0.03982</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.03982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.066182</td>\n",
       "      <td>-0.269251</td>\n",
       "      <td>1.196481</td>\n",
       "      <td>5.972851</td>\n",
       "      <td>1.200588</td>\n",
       "      <td>-2.117412</td>\n",
       "      <td>-0.032504</td>\n",
       "      <td>0.681507</td>\n",
       "      <td>-0.429389</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.051434</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.072836</td>\n",
       "      <td>-0.03982</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>-0.03982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Battery Voltage AVG  Temperature AVG  Relative Humidity AVG  \\\n",
       "0             2.003522        -1.580891              -1.269311   \n",
       "1             3.506158        -1.033951              -1.180109   \n",
       "2            -0.587638         0.630261              -0.930861   \n",
       "3             0.418063         0.029488              -0.880092   \n",
       "4            -4.066182        -0.269251               1.196481   \n",
       "\n",
       "   Wind Speed Daily AVG  Wind Direction AVG  Solare Radiation AVG         0  \\\n",
       "0              1.895222           -0.958813             -1.567664 -0.032504   \n",
       "1             -0.902775           -0.414849             -1.520897 -0.032504   \n",
       "2              0.728090            1.139477             -1.115850 -0.032504   \n",
       "3              0.993477            1.366280             -0.771758 -0.032504   \n",
       "4              5.972851            1.200588             -2.117412 -0.032504   \n",
       "\n",
       "          1         2         3  ...       194       195       196       197  \\\n",
       "0  0.681507 -0.429389 -0.051434  ... -0.022978 -0.022978 -0.051434 -0.022978   \n",
       "1  0.681507 -0.429389 -0.051434  ... -0.022978 -0.022978 -0.051434 -0.022978   \n",
       "2  0.681507 -0.429389 -0.051434  ... -0.022978 -0.022978 -0.051434 -0.022978   \n",
       "3 -1.467337 -0.429389 -0.051434  ... -0.022978 -0.022978 -0.051434 -0.022978   \n",
       "4  0.681507 -0.429389 -0.051434  ... -0.022978 -0.022978 -0.051434 -0.022978   \n",
       "\n",
       "        198       199      200       201       202      203  \n",
       "0 -0.056359 -0.072836 -0.03982 -0.056359 -0.022978 -0.03982  \n",
       "1 -0.056359 -0.072836 -0.03982 -0.056359 -0.022978 -0.03982  \n",
       "2 -0.056359 -0.072836 -0.03982 -0.056359 -0.022978 -0.03982  \n",
       "3 -0.056359 -0.072836 -0.03982 -0.056359 -0.022978 -0.03982  \n",
       "4 -0.056359 -0.072836 -0.03982 -0.056359 -0.022978 -0.03982  \n",
       "\n",
       "[5 rows x 232 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "all_columns = ranier_features_df.columns\n",
    "\n",
    "ranier_features_df[all_columns] = scaler.fit_transform(ranier_features_df[all_columns])\n",
    "ranier_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0f763",
   "metadata": {},
   "source": [
    "### 4. Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f97dde2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 training data shape = ((1364, 232), (1364, 1))\n",
      "Fold 1 validation data shape = ((341, 232), (341, 1))\n",
      "Fold 2 training data shape = ((1364, 232), (1364, 1))\n",
      "Fold 2 validation data shape = ((341, 232), (341, 1))\n",
      "Fold 3 training data shape = ((1364, 232), (1364, 1))\n",
      "Fold 3 validation data shape = ((341, 232), (341, 1))\n",
      "Fold 4 training data shape = ((1364, 232), (1364, 1))\n",
      "Fold 4 validation data shape = ((341, 232), (341, 1))\n",
      "Fold 5 training data shape = ((1364, 232), (1364, 1))\n",
      "Fold 5 validation data shape = ((341, 232), (341, 1))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# First extract test data and store it in x_test, y_test\n",
    "features = ranier_features_df.to_numpy()\n",
    "labels = ranier_labels_df.to_numpy()\n",
    "_x, x_test, _y, y_test = train_test_split(features, labels, test_size=0.10, random_state=42)\n",
    "\n",
    "# set k = 5\n",
    "k = 5\n",
    "\n",
    "kfold_spliiter = KFold(n_splits=k)\n",
    "\n",
    "folds_data = []\n",
    "\n",
    "fold = 1\n",
    "for train_index, validation_index in kfold_spliiter.split(_x):\n",
    "    x_train , x_valid = _x[train_index,:],_x[validation_index,:]\n",
    "    y_train , y_valid = _y[train_index,:] , _y[validation_index,:]\n",
    "    print (f\"Fold {fold} training data shape = {(x_train.shape,y_train.shape)}\")\n",
    "    print (f\"Fold {fold} validation data shape = {(x_valid.shape,y_valid.shape)}\")\n",
    "    fold+=1\n",
    "    folds_data.append((x_train,y_train,x_valid,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f59a05",
   "metadata": {},
   "source": [
    "### 5. Define the Models: Logisitic Regression, SVC, and Gradient Boosting Classifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "911fa0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "lr_vanilla = LogisticRegression(penalty= 'none')\n",
    "svm_linear = SVC(kernel=\"linear\")\n",
    "grad_boost = GradientBoostingClassifier()\n",
    "\n",
    "# Keep all the models in a dictionary\n",
    "\n",
    "all_models = {\"lr_vanilla\":lr_vanilla, \n",
    "              #\"lr_L2\":lr_L2,\n",
    "              \"svm_linear\":svm_linear,\n",
    "             # \"svm_poly\":svm_poly,\n",
    "             \"grad_boost\":grad_boost}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db8e757",
   "metadata": {},
   "source": [
    "### Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07eb14a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lr_vanilla ...\n",
      "Average training accuracy for model lr_vanilla = 0.7145161290322581\n",
      "Average validation accuracy for model lr_vanilla = 0.619941348973607\n",
      "-----------------------------------\n",
      "Evaluating svm_linear ...\n",
      "Average training accuracy for model svm_linear = 0.709090909090909\n",
      "Average validation accuracy for model svm_linear = 0.6205278592375366\n",
      "-----------------------------------\n",
      "Evaluating grad_boost ...\n",
      "Average training accuracy for model grad_boost = 0.7118768328445748\n",
      "Average validation accuracy for model grad_boost = 0.6416422287390029\n",
      "-----------------------------------\n",
      "Best model for the task is grad_boost which offers the validation accuracy of 0.6416422287390029\n"
     ]
    }
   ],
   "source": [
    "best_validation_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "best_model = None\n",
    "\n",
    "# Iterate over all models\n",
    "for model_name in all_models.keys():\n",
    "    \n",
    "    print (f\"Evaluating {model_name} ...\")\n",
    "    model = all_models[model_name]\n",
    "    \n",
    "    # Store training and validation accuracies for all folds\n",
    "    train_acc_for_all_folds = []\n",
    "    valid_acc_for_all_folds = []\n",
    "    \n",
    "    #Iterate over all folds\n",
    "    for i, fold in enumerate(folds_data):\n",
    "        x_train, y_train, x_valid, y_valid = fold\n",
    "\n",
    "        # Train the model\n",
    "        _ = model.fit(x_train,y_train.flatten())\n",
    "\n",
    "        # Evluate model on training data\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        \n",
    "        # Evaluate the model on validation data\n",
    "        y_pred_valid = model.predict(x_valid)\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        train_acc = accuracy_score(y_pred_train , y_train.flatten())\n",
    "        \n",
    "        # Store training accuracy for each folds\n",
    "        train_acc_for_all_folds.append(train_acc)\n",
    "        \n",
    "        # Compute validation accuracy\n",
    "        valid_acc = accuracy_score(y_pred_valid , y_valid.flatten())\n",
    "\n",
    "        # Store validation accuracy for each folds\n",
    "        valid_acc_for_all_folds.append(valid_acc)\n",
    "    \n",
    "    #average training accuracy across k folds\n",
    "    avg_training_acc = sum(train_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average training accuracy for model {model_name} = {avg_training_acc}\")\n",
    "    \n",
    "    #average validation accuracy across k folds\n",
    "    avg_validation_acc = sum(valid_acc_for_all_folds)/k\n",
    "    \n",
    "    print (f\"Average validation accuracy for model {model_name} = {avg_validation_acc}\")\n",
    "    \n",
    "    # Select best model based on average validation accuracy\n",
    "    if avg_validation_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = avg_validation_acc\n",
    "        best_model_name = model_name\n",
    "        best_model = model\n",
    "    print (f\"-----------------------------------\")\n",
    "\n",
    "print (f\"Best model for the task is {best_model_name} which offers the validation accuracy of {best_validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc952aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy for model lr_vanilla = 0.6263929618768328\n",
      "Mean cross validation accuracy for model svm_linear = 0.6269794721407624\n",
      "Mean cross validation accuracy for model grad_boost = 0.6439882697947213\n",
      "Best model is grad_boost with 5-fold accuracy of 0.6439882697947213\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# First extract our test data and store it in x_test, y_test\n",
    "features = ranier_features_df.to_numpy()\n",
    "labels = ranier_labels_df.to_numpy()\n",
    "_x, x_test, _y, y_test = train_test_split(features, labels, test_size=0.10, random_state=42)\n",
    "\n",
    "k = 5 # 5-fold\n",
    "\n",
    "# Use sklearn's cross validation score directly\n",
    "# Speed up training using n_jobs parameter which specifies how many cpu_cores to use\n",
    "\n",
    "best_model_name = \"\"\n",
    "best_model_valid_accuracy = 0\n",
    "best_model = None\n",
    "\n",
    "for model_name in all_models.keys():\n",
    "    model = all_models[model_name]\n",
    "    cv_scores = cross_val_score(model,_x,_y.flatten(), cv=k, n_jobs=4)\n",
    "    average_cv_score = cv_scores.mean()\n",
    "    print (f\"Mean cross validation accuracy for model {model_name} = {average_cv_score}\")\n",
    "\n",
    "    if average_cv_score > best_model_valid_accuracy :\n",
    "        best_model_name = model_name\n",
    "        best_model_valid_accuracy  = average_cv_score\n",
    "        best_model = model\n",
    "\n",
    "print (f\"Best model is {best_model_name} with {k}-fold accuracy of {best_model_valid_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b65b58",
   "metadata": {},
   "source": [
    "The best model in both the cross valdation and the training accuracy tests is the gradient boost classifier. It received a validation accuracy score of .643 compared to 0.626 for logistic regression and 0.626 for SVC. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c550f43",
   "metadata": {},
   "source": [
    "### Three Model Candidates - Logistic Regression, SVC, and Gradient Descent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d48b4",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235b67ae",
   "metadata": {},
   "source": [
    "Feature ablation of Gradient Boost Classifier model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c856555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature Battery Voltage AVG\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature Temperature AVG\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature Relative Humidity AVG\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature Wind Speed Daily AVG\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature Wind Direction AVG\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature Solare Radiation AVG\n",
      "Mean cross validation accuracy = 0.6252199413489736\n",
      "Removing feature 0\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 1\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 2\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 3\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 4\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 5\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 6\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 7\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 8\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 9\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 10\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 11\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 12\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 13\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 14\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 15\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 16\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 17\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 18\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 19\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 20\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 21\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 0\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 1\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 2\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 3\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 4\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 5\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 6\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 7\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 8\n",
      "Mean cross validation accuracy = 0.6293255131964809\n",
      "Removing feature 9\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 10\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 11\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 12\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 13\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 14\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 15\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 16\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 17\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 18\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 19\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 20\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 21\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 22\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 23\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 24\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 25\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 26\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 27\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 28\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 29\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 30\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 31\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 32\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 33\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 34\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 35\n",
      "Mean cross validation accuracy = 0.6234604105571847\n",
      "Removing feature 36\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 37\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 38\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 39\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 40\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 41\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 42\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 43\n",
      "Mean cross validation accuracy = 0.6211143695014663\n",
      "Removing feature 44\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 45\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 46\n",
      "Mean cross validation accuracy = 0.6234604105571847\n",
      "Removing feature 47\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 48\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 49\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 50\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 51\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 52\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 53\n",
      "Mean cross validation accuracy = 0.6222873900293255\n",
      "Removing feature 54\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 55\n",
      "Mean cross validation accuracy = 0.6228739002932551\n",
      "Removing feature 56\n",
      "Mean cross validation accuracy = 0.6217008797653959\n",
      "Removing feature 57\n",
      "Mean cross validation accuracy = 0.6228739002932551\n",
      "Removing feature 58\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 59\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 60\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 61\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 62\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 63\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 64\n",
      "Mean cross validation accuracy = 0.6252199413489736\n",
      "Removing feature 65\n",
      "Mean cross validation accuracy = 0.6240469208211143\n",
      "Removing feature 66\n",
      "Mean cross validation accuracy = 0.624633431085044\n",
      "Removing feature 67\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 68\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 69\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 70\n",
      "Mean cross validation accuracy = 0.6240469208211143\n",
      "Removing feature 71\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 72\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 73\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 74\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 75\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 76\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 77\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 78\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 79\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 80\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 81\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 82\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 83\n",
      "Mean cross validation accuracy = 0.624633431085044\n",
      "Removing feature 84\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 85\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 86\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 87\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 88\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 89\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 90\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 91\n",
      "Mean cross validation accuracy = 0.6222873900293255\n",
      "Removing feature 92\n",
      "Mean cross validation accuracy = 0.6240469208211143\n",
      "Removing feature 93\n",
      "Mean cross validation accuracy = 0.6240469208211143\n",
      "Removing feature 94\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 95\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 96\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 97\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 98\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 99\n",
      "Mean cross validation accuracy = 0.6252199413489736\n",
      "Removing feature 100\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 101\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 102\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 103\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 104\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 105\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 106\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 107\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 108\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 109\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 110\n",
      "Mean cross validation accuracy = 0.6228739002932551\n",
      "Removing feature 111\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 112\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 113\n",
      "Mean cross validation accuracy = 0.6299120234604105\n",
      "Removing feature 114\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 115\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 116\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 117\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 118\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 119\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 120\n",
      "Mean cross validation accuracy = 0.6252199413489736\n",
      "Removing feature 121\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 122\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 123\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 124\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 125\n",
      "Mean cross validation accuracy = 0.6252199413489736\n",
      "Removing feature 126\n",
      "Mean cross validation accuracy = 0.6228739002932551\n",
      "Removing feature 127\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 128\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 129\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 130\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 131\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 132\n",
      "Mean cross validation accuracy = 0.6293255131964809\n",
      "Removing feature 133\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 134\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 135\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 136\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 137\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 138\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 139\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 140\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 141\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 142\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 143\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 144\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 145\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 146\n",
      "Mean cross validation accuracy = 0.6252199413489736\n",
      "Removing feature 147\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 148\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 149\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 150\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 151\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 152\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 153\n",
      "Mean cross validation accuracy = 0.624633431085044\n",
      "Removing feature 154\n",
      "Mean cross validation accuracy = 0.6234604105571847\n",
      "Removing feature 155\n",
      "Mean cross validation accuracy = 0.6252199413489736\n",
      "Removing feature 156\n",
      "Mean cross validation accuracy = 0.6252199413489736\n",
      "Removing feature 157\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 158\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 159\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 160\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 161\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 162\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 163\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 164\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 165\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 166\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 167\n",
      "Mean cross validation accuracy = 0.6222873900293255\n",
      "Removing feature 168\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 169\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 170\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 171\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 172\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 173\n",
      "Mean cross validation accuracy = 0.6181818181818182\n",
      "Removing feature 174\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 175\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 176\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 177\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 178\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 179\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 180\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 181\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 182\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 183\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 184\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 185\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 186\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 187\n",
      "Mean cross validation accuracy = 0.6222873900293255\n",
      "Removing feature 188\n",
      "Mean cross validation accuracy = 0.6234604105571847\n",
      "Removing feature 189\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 190\n",
      "Mean cross validation accuracy = 0.6258064516129032\n",
      "Removing feature 191\n",
      "Mean cross validation accuracy = 0.6205278592375366\n",
      "Removing feature 192\n",
      "Mean cross validation accuracy = 0.6240469208211143\n",
      "Removing feature 193\n",
      "Mean cross validation accuracy = 0.6263929618768328\n",
      "Removing feature 194\n",
      "Mean cross validation accuracy = 0.6252199413489736\n",
      "Removing feature 195\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 196\n",
      "Mean cross validation accuracy = 0.6269794721407624\n",
      "Removing feature 197\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 198\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 199\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 200\n",
      "Mean cross validation accuracy = 0.6281524926686217\n",
      "Removing feature 201\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 202\n",
      "Mean cross validation accuracy = 0.6275659824046921\n",
      "Removing feature 203\n",
      "Mean cross validation accuracy = 0.6269794721407624\n"
     ]
    }
   ],
   "source": [
    "# Run ablation tests on the best model\n",
    "best_model = LogisticRegression()\n",
    "\n",
    "feature_names = ranier_features_df.columns\n",
    "\n",
    "# Maintain an accuracy dictionary\n",
    "\n",
    "accuracy_drop_log = {\"No ablation\":0}\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    # Drop one feature at a time\n",
    "    feature_name = feature_names[i]\n",
    "    print (f\"Removing feature {feature_name}\")\n",
    "\n",
    "    x_ablated = numpy.delete(_x,i,axis=1) # axis = 1 means columns\n",
    "    \n",
    "    cv_scores = cross_val_score(best_model,x_ablated,_y.flatten(), cv=k, n_jobs=4)\n",
    "    average_cv_score = cv_scores.mean()\n",
    "    print (f\"Mean cross validation accuracy = {average_cv_score}\")\n",
    "    accuracy_drop_log[feature_name] = best_model_valid_accuracy-average_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f614977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are ranked from best to worst (based on how removing them impacts the accuracy of grad_boost)\n",
      "**************************************\n",
      "Feature 1.173, drop in acc 0.02580645161290318\n",
      "Feature 2.191, drop in acc 0.02346041055718473\n",
      "Feature 3.43, drop in acc 0.02287390029325509\n",
      "Feature 4.56, drop in acc 0.02228739002932545\n",
      "Feature 5.53, drop in acc 0.02170087976539581\n",
      "Feature 6.91, drop in acc 0.02170087976539581\n",
      "Feature 7.167, drop in acc 0.02170087976539581\n",
      "Feature 8.187, drop in acc 0.02170087976539581\n",
      "Feature 9.55, drop in acc 0.02111436950146628\n",
      "Feature 10.57, drop in acc 0.02111436950146628\n",
      "Feature 11.110, drop in acc 0.02111436950146628\n",
      "Feature 12.126, drop in acc 0.02111436950146628\n",
      "Feature 13.35, drop in acc 0.02052785923753664\n",
      "Feature 14.46, drop in acc 0.02052785923753664\n",
      "Feature 15.154, drop in acc 0.02052785923753664\n",
      "Feature 16.188, drop in acc 0.02052785923753664\n",
      "Feature 17.65, drop in acc 0.019941348973606998\n",
      "Feature 18.70, drop in acc 0.019941348973606998\n",
      "Feature 19.92, drop in acc 0.019941348973606998\n",
      "Feature 20.93, drop in acc 0.019941348973606998\n",
      "Feature 21.192, drop in acc 0.019941348973606998\n",
      "Feature 22.66, drop in acc 0.019354838709677358\n",
      "Feature 23.83, drop in acc 0.019354838709677358\n",
      "Feature 24.153, drop in acc 0.019354838709677358\n",
      "Feature 25.Solare Radiation AVG, drop in acc 0.018768328445747717\n",
      "Feature 26.64, drop in acc 0.018768328445747717\n",
      "Feature 27.99, drop in acc 0.018768328445747717\n",
      "Feature 28.120, drop in acc 0.018768328445747717\n",
      "Feature 29.125, drop in acc 0.018768328445747717\n",
      "Feature 30.146, drop in acc 0.018768328445747717\n",
      "Feature 31.155, drop in acc 0.018768328445747717\n",
      "Feature 32.156, drop in acc 0.018768328445747717\n",
      "Feature 33.194, drop in acc 0.018768328445747717\n",
      "Feature 34.2, drop in acc 0.018181818181818188\n",
      "Feature 35.3, drop in acc 0.018181818181818188\n",
      "Feature 36.6, drop in acc 0.018181818181818188\n",
      "Feature 37.20, drop in acc 0.018181818181818188\n",
      "Feature 38.21, drop in acc 0.018181818181818188\n",
      "Feature 39.24, drop in acc 0.018181818181818188\n",
      "Feature 40.30, drop in acc 0.018181818181818188\n",
      "Feature 41.72, drop in acc 0.018181818181818188\n",
      "Feature 42.84, drop in acc 0.018181818181818188\n",
      "Feature 43.86, drop in acc 0.018181818181818188\n",
      "Feature 44.89, drop in acc 0.018181818181818188\n",
      "Feature 45.100, drop in acc 0.018181818181818188\n",
      "Feature 46.123, drop in acc 0.018181818181818188\n",
      "Feature 47.151, drop in acc 0.018181818181818188\n",
      "Feature 48.186, drop in acc 0.018181818181818188\n",
      "Feature 49.190, drop in acc 0.018181818181818188\n",
      "Feature 50.5, drop in acc 0.017595307917888547\n",
      "Feature 51.17, drop in acc 0.017595307917888547\n",
      "Feature 52.22, drop in acc 0.017595307917888547\n",
      "Feature 53.29, drop in acc 0.017595307917888547\n",
      "Feature 54.33, drop in acc 0.017595307917888547\n",
      "Feature 55.38, drop in acc 0.017595307917888547\n",
      "Feature 56.49, drop in acc 0.017595307917888547\n",
      "Feature 57.59, drop in acc 0.017595307917888547\n",
      "Feature 58.61, drop in acc 0.017595307917888547\n",
      "Feature 59.63, drop in acc 0.017595307917888547\n",
      "Feature 60.73, drop in acc 0.017595307917888547\n",
      "Feature 61.75, drop in acc 0.017595307917888547\n",
      "Feature 62.76, drop in acc 0.017595307917888547\n",
      "Feature 63.87, drop in acc 0.017595307917888547\n",
      "Feature 64.97, drop in acc 0.017595307917888547\n",
      "Feature 65.103, drop in acc 0.017595307917888547\n",
      "Feature 66.124, drop in acc 0.017595307917888547\n",
      "Feature 67.141, drop in acc 0.017595307917888547\n",
      "Feature 68.148, drop in acc 0.017595307917888547\n",
      "Feature 69.149, drop in acc 0.017595307917888547\n",
      "Feature 70.168, drop in acc 0.017595307917888547\n",
      "Feature 71.174, drop in acc 0.017595307917888547\n",
      "Feature 72.179, drop in acc 0.017595307917888547\n",
      "Feature 73.180, drop in acc 0.017595307917888547\n",
      "Feature 74.193, drop in acc 0.017595307917888547\n",
      "Feature 75.Battery Voltage AVG, drop in acc 0.017008797653958907\n",
      "Feature 76.Relative Humidity AVG, drop in acc 0.017008797653958907\n",
      "Feature 77.1, drop in acc 0.017008797653958907\n",
      "Feature 78.16, drop in acc 0.017008797653958907\n",
      "Feature 79.18, drop in acc 0.017008797653958907\n",
      "Feature 80.23, drop in acc 0.017008797653958907\n",
      "Feature 81.25, drop in acc 0.017008797653958907\n",
      "Feature 82.26, drop in acc 0.017008797653958907\n",
      "Feature 83.28, drop in acc 0.017008797653958907\n",
      "Feature 84.32, drop in acc 0.017008797653958907\n",
      "Feature 85.37, drop in acc 0.017008797653958907\n",
      "Feature 86.39, drop in acc 0.017008797653958907\n",
      "Feature 87.40, drop in acc 0.017008797653958907\n",
      "Feature 88.44, drop in acc 0.017008797653958907\n",
      "Feature 89.45, drop in acc 0.017008797653958907\n",
      "Feature 90.48, drop in acc 0.017008797653958907\n",
      "Feature 91.51, drop in acc 0.017008797653958907\n",
      "Feature 92.52, drop in acc 0.017008797653958907\n",
      "Feature 93.58, drop in acc 0.017008797653958907\n",
      "Feature 94.67, drop in acc 0.017008797653958907\n",
      "Feature 95.78, drop in acc 0.017008797653958907\n",
      "Feature 96.80, drop in acc 0.017008797653958907\n",
      "Feature 97.82, drop in acc 0.017008797653958907\n",
      "Feature 98.88, drop in acc 0.017008797653958907\n",
      "Feature 99.102, drop in acc 0.017008797653958907\n",
      "Feature 100.105, drop in acc 0.017008797653958907\n",
      "Feature 101.106, drop in acc 0.017008797653958907\n",
      "Feature 102.108, drop in acc 0.017008797653958907\n",
      "Feature 103.116, drop in acc 0.017008797653958907\n",
      "Feature 104.118, drop in acc 0.017008797653958907\n",
      "Feature 105.119, drop in acc 0.017008797653958907\n",
      "Feature 106.128, drop in acc 0.017008797653958907\n",
      "Feature 107.129, drop in acc 0.017008797653958907\n",
      "Feature 108.131, drop in acc 0.017008797653958907\n",
      "Feature 109.134, drop in acc 0.017008797653958907\n",
      "Feature 110.137, drop in acc 0.017008797653958907\n",
      "Feature 111.152, drop in acc 0.017008797653958907\n",
      "Feature 112.160, drop in acc 0.017008797653958907\n",
      "Feature 113.163, drop in acc 0.017008797653958907\n",
      "Feature 114.165, drop in acc 0.017008797653958907\n",
      "Feature 115.175, drop in acc 0.017008797653958907\n",
      "Feature 116.176, drop in acc 0.017008797653958907\n",
      "Feature 117.185, drop in acc 0.017008797653958907\n",
      "Feature 118.189, drop in acc 0.017008797653958907\n",
      "Feature 119.195, drop in acc 0.017008797653958907\n",
      "Feature 120.196, drop in acc 0.017008797653958907\n",
      "Feature 121.203, drop in acc 0.017008797653958907\n",
      "Feature 122.Wind Direction AVG, drop in acc 0.016422287390029267\n",
      "Feature 123.0, drop in acc 0.016422287390029267\n",
      "Feature 124.7, drop in acc 0.016422287390029267\n",
      "Feature 125.9, drop in acc 0.016422287390029267\n",
      "Feature 126.10, drop in acc 0.016422287390029267\n",
      "Feature 127.11, drop in acc 0.016422287390029267\n",
      "Feature 128.14, drop in acc 0.016422287390029267\n",
      "Feature 129.19, drop in acc 0.016422287390029267\n",
      "Feature 130.27, drop in acc 0.016422287390029267\n",
      "Feature 131.31, drop in acc 0.016422287390029267\n",
      "Feature 132.34, drop in acc 0.016422287390029267\n",
      "Feature 133.41, drop in acc 0.016422287390029267\n",
      "Feature 134.42, drop in acc 0.016422287390029267\n",
      "Feature 135.47, drop in acc 0.016422287390029267\n",
      "Feature 136.50, drop in acc 0.016422287390029267\n",
      "Feature 137.60, drop in acc 0.016422287390029267\n",
      "Feature 138.62, drop in acc 0.016422287390029267\n",
      "Feature 139.69, drop in acc 0.016422287390029267\n",
      "Feature 140.74, drop in acc 0.016422287390029267\n",
      "Feature 141.77, drop in acc 0.016422287390029267\n",
      "Feature 142.85, drop in acc 0.016422287390029267\n",
      "Feature 143.94, drop in acc 0.016422287390029267\n",
      "Feature 144.96, drop in acc 0.016422287390029267\n",
      "Feature 145.101, drop in acc 0.016422287390029267\n",
      "Feature 146.107, drop in acc 0.016422287390029267\n",
      "Feature 147.109, drop in acc 0.016422287390029267\n",
      "Feature 148.117, drop in acc 0.016422287390029267\n",
      "Feature 149.121, drop in acc 0.016422287390029267\n",
      "Feature 150.122, drop in acc 0.016422287390029267\n",
      "Feature 151.127, drop in acc 0.016422287390029267\n",
      "Feature 152.135, drop in acc 0.016422287390029267\n",
      "Feature 153.139, drop in acc 0.016422287390029267\n",
      "Feature 154.142, drop in acc 0.016422287390029267\n",
      "Feature 155.144, drop in acc 0.016422287390029267\n",
      "Feature 156.145, drop in acc 0.016422287390029267\n",
      "Feature 157.147, drop in acc 0.016422287390029267\n",
      "Feature 158.150, drop in acc 0.016422287390029267\n",
      "Feature 159.166, drop in acc 0.016422287390029267\n",
      "Feature 160.170, drop in acc 0.016422287390029267\n",
      "Feature 161.178, drop in acc 0.016422287390029267\n",
      "Feature 162.183, drop in acc 0.016422287390029267\n",
      "Feature 163.184, drop in acc 0.016422287390029267\n",
      "Feature 164.202, drop in acc 0.016422287390029267\n",
      "Feature 165.Temperature AVG, drop in acc 0.015835777126099626\n",
      "Feature 166.Wind Speed Daily AVG, drop in acc 0.015835777126099626\n",
      "Feature 167.12, drop in acc 0.015835777126099626\n",
      "Feature 168.15, drop in acc 0.015835777126099626\n",
      "Feature 169.36, drop in acc 0.015835777126099626\n",
      "Feature 170.71, drop in acc 0.015835777126099626\n",
      "Feature 171.81, drop in acc 0.015835777126099626\n",
      "Feature 172.95, drop in acc 0.015835777126099626\n",
      "Feature 173.98, drop in acc 0.015835777126099626\n",
      "Feature 174.104, drop in acc 0.015835777126099626\n",
      "Feature 175.111, drop in acc 0.015835777126099626\n",
      "Feature 176.114, drop in acc 0.015835777126099626\n",
      "Feature 177.130, drop in acc 0.015835777126099626\n",
      "Feature 178.133, drop in acc 0.015835777126099626\n",
      "Feature 179.143, drop in acc 0.015835777126099626\n",
      "Feature 180.157, drop in acc 0.015835777126099626\n",
      "Feature 181.158, drop in acc 0.015835777126099626\n",
      "Feature 182.159, drop in acc 0.015835777126099626\n",
      "Feature 183.161, drop in acc 0.015835777126099626\n",
      "Feature 184.164, drop in acc 0.015835777126099626\n",
      "Feature 185.177, drop in acc 0.015835777126099626\n",
      "Feature 186.197, drop in acc 0.015835777126099626\n",
      "Feature 187.199, drop in acc 0.015835777126099626\n",
      "Feature 188.200, drop in acc 0.015835777126099626\n",
      "Feature 189.4, drop in acc 0.015249266862170097\n",
      "Feature 190.13, drop in acc 0.015249266862170097\n",
      "Feature 191.54, drop in acc 0.015249266862170097\n",
      "Feature 192.68, drop in acc 0.015249266862170097\n",
      "Feature 193.79, drop in acc 0.015249266862170097\n",
      "Feature 194.90, drop in acc 0.015249266862170097\n",
      "Feature 195.112, drop in acc 0.015249266862170097\n",
      "Feature 196.115, drop in acc 0.015249266862170097\n",
      "Feature 197.136, drop in acc 0.015249266862170097\n",
      "Feature 198.138, drop in acc 0.015249266862170097\n",
      "Feature 199.140, drop in acc 0.015249266862170097\n",
      "Feature 200.162, drop in acc 0.015249266862170097\n",
      "Feature 201.169, drop in acc 0.015249266862170097\n",
      "Feature 202.171, drop in acc 0.015249266862170097\n",
      "Feature 203.172, drop in acc 0.015249266862170097\n",
      "Feature 204.181, drop in acc 0.015249266862170097\n",
      "Feature 205.182, drop in acc 0.015249266862170097\n",
      "Feature 206.198, drop in acc 0.015249266862170097\n",
      "Feature 207.201, drop in acc 0.015249266862170097\n",
      "Feature 208.8, drop in acc 0.014662756598240456\n",
      "Feature 209.132, drop in acc 0.014662756598240456\n",
      "Feature 210.113, drop in acc 0.014076246334310816\n"
     ]
    }
   ],
   "source": [
    "def criteria(l):\n",
    "    return l[1]\n",
    "\n",
    "sorted_accs =  sorted(accuracy_drop_log.items(),key=criteria, reverse=True)\n",
    "\n",
    "print (f\"Features are ranked from best to worst (based on how removing them impacts the accuracy of {best_model_name})\")\n",
    "print (f\"**************************************\")\n",
    "\n",
    "i=1\n",
    "for entry in sorted_accs:\n",
    "    feature_name = entry[0]\n",
    "    acc_drop = entry[1]\n",
    "    \n",
    "    if feature_name != \"No ablation\":\n",
    "        print (f\"Feature {i}.{feature_name}, drop in acc {acc_drop}\")\n",
    "        i=i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56960032",
   "metadata": {},
   "source": [
    "#### B. SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6693b3cd",
   "metadata": {},
   "source": [
    "Feature ablation of SVC model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c03693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature Battery Voltage AVG\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature Temperature AVG\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature Relative Humidity AVG\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature Wind Speed Daily AVG\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature Wind Direction AVG\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature Solare Radiation AVG\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 0\n",
      "Mean cross validation accuracy = 0.6316715542521993\n",
      "Removing feature 1\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 2\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 3\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 4\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 5\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 6\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 7\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 8\n",
      "Mean cross validation accuracy = 0.6304985337243402\n",
      "Removing feature 9\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 10\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 11\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 12\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 13\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 14\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 15\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 16\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 17\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 18\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 19\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 20\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 21\n",
      "Mean cross validation accuracy = 0.6240469208211143\n",
      "Removing feature 0\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 1\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 2\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 3\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 4\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 5\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 6\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 7\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 8\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 9\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 10\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 11\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 12\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 13\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 14\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 15\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 16\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 17\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 18\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 19\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 20\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 21\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 22\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 23\n",
      "Mean cross validation accuracy = 0.632258064516129\n",
      "Removing feature 24\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 25\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 26\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 27\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 28\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 29\n",
      "Mean cross validation accuracy = 0.632258064516129\n",
      "Removing feature 30\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 31\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 32\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 33\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 34\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 35\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 36\n",
      "Mean cross validation accuracy = 0.632258064516129\n",
      "Removing feature 37\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 38\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 39\n",
      "Mean cross validation accuracy = 0.632258064516129\n",
      "Removing feature 40\n",
      "Mean cross validation accuracy = 0.6316715542521993\n",
      "Removing feature 41\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 42\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 43\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 44\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 45\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 46\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 47\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 48\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 49\n",
      "Mean cross validation accuracy = 0.6363636363636364\n",
      "Removing feature 50\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 51\n",
      "Mean cross validation accuracy = 0.6316715542521993\n",
      "Removing feature 52\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 53\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 54\n",
      "Mean cross validation accuracy = 0.6310850439882698\n",
      "Removing feature 55\n",
      "Mean cross validation accuracy = 0.6381231671554252\n",
      "Removing feature 56\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 57\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 58\n",
      "Mean cross validation accuracy = 0.6316715542521993\n",
      "Removing feature 59\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 60\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 61\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 62\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 63\n",
      "Mean cross validation accuracy = 0.6316715542521993\n",
      "Removing feature 64\n",
      "Mean cross validation accuracy = 0.6381231671554252\n",
      "Removing feature 65\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 66\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 67\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 68\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 69\n",
      "Mean cross validation accuracy = 0.6363636363636364\n",
      "Removing feature 70\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 71\n",
      "Mean cross validation accuracy = 0.6299120234604105\n",
      "Removing feature 72\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 73\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 74\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 75\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 76\n",
      "Mean cross validation accuracy = 0.6310850439882698\n",
      "Removing feature 77\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 78\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 79\n",
      "Mean cross validation accuracy = 0.6316715542521993\n",
      "Removing feature 80\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 81\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 82\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 83\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 84\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 85\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 86\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 87\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 88\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 89\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 90\n",
      "Mean cross validation accuracy = 0.6381231671554252\n",
      "Removing feature 91\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 92\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 93\n",
      "Mean cross validation accuracy = 0.6357771260997067\n",
      "Removing feature 94\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 95\n",
      "Mean cross validation accuracy = 0.6357771260997067\n",
      "Removing feature 96\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 97\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 98\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 99\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 100\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 101\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 102\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 103\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 104\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 105\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 106\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 107\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 108\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 109\n",
      "Mean cross validation accuracy = 0.6310850439882698\n",
      "Removing feature 110\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 111\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 112\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 113\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 114\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 115\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 116\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 117\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 118\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 119\n",
      "Mean cross validation accuracy = 0.6310850439882698\n",
      "Removing feature 120\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 121\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 122\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 123\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 124\n",
      "Mean cross validation accuracy = 0.6304985337243402\n",
      "Removing feature 125\n",
      "Mean cross validation accuracy = 0.632258064516129\n",
      "Removing feature 126\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 127\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 128\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 129\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 130\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 131\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 132\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 133\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 134\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 135\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 136\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 137\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 138\n",
      "Mean cross validation accuracy = 0.6363636363636364\n",
      "Removing feature 139\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 140\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 141\n",
      "Mean cross validation accuracy = 0.636950146627566\n",
      "Removing feature 142\n",
      "Mean cross validation accuracy = 0.636950146627566\n",
      "Removing feature 143\n",
      "Mean cross validation accuracy = 0.6299120234604105\n",
      "Removing feature 144\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 145\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 146\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 147\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 148\n",
      "Mean cross validation accuracy = 0.6351906158357771\n",
      "Removing feature 149\n",
      "Mean cross validation accuracy = 0.636950146627566\n",
      "Removing feature 150\n",
      "Mean cross validation accuracy = 0.6363636363636364\n",
      "Removing feature 151\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 152\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 153\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 154\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 155\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 156\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 157\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 158\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 159\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 160\n",
      "Mean cross validation accuracy = 0.636950146627566\n",
      "Removing feature 161\n",
      "Mean cross validation accuracy = 0.632258064516129\n",
      "Removing feature 162\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 163\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 164\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 165\n",
      "Mean cross validation accuracy = 0.6363636363636364\n",
      "Removing feature 166\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 167\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 168\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 169\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 170\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 171\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 172\n",
      "Mean cross validation accuracy = 0.632258064516129\n",
      "Removing feature 173\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 174\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 175\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 176\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 177\n",
      "Mean cross validation accuracy = 0.6299120234604105\n",
      "Removing feature 178\n",
      "Mean cross validation accuracy = 0.6304985337243402\n",
      "Removing feature 179\n",
      "Mean cross validation accuracy = 0.6316715542521993\n",
      "Removing feature 180\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 181\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 182\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 183\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 184\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 185\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 186\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 187\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 188\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 189\n",
      "Mean cross validation accuracy = 0.6328445747800586\n",
      "Removing feature 190\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 191\n",
      "Mean cross validation accuracy = 0.6346041055718474\n",
      "Removing feature 192\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 193\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 194\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 195\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 196\n",
      "Mean cross validation accuracy = 0.6304985337243402\n",
      "Removing feature 197\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 198\n",
      "Mean cross validation accuracy = 0.6299120234604105\n",
      "Removing feature 199\n",
      "Mean cross validation accuracy = 0.6287390029325512\n",
      "Removing feature 200\n",
      "Mean cross validation accuracy = 0.632258064516129\n",
      "Removing feature 201\n",
      "Mean cross validation accuracy = 0.6357771260997067\n",
      "Removing feature 202\n",
      "Mean cross validation accuracy = 0.6334310850439883\n",
      "Removing feature 203\n",
      "Mean cross validation accuracy = 0.6340175953079179\n"
     ]
    }
   ],
   "source": [
    "best_model = SVC()\n",
    "\n",
    "feature_names = ranier_features_df.columns\n",
    "\n",
    "# Maintain an accuracy dictionary\n",
    "\n",
    "accuracy_drop_log = {\"No ablation\":0}\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    # Drop one feature at a time\n",
    "    feature_name = feature_names[i]\n",
    "    print (f\"Removing feature {feature_name}\")\n",
    "\n",
    "    x_ablated = numpy.delete(_x,i,axis=1) # axis = 1 means columns\n",
    "    \n",
    "    cv_scores = cross_val_score(best_model,x_ablated,_y.flatten(), cv=k, n_jobs=4)\n",
    "    average_cv_score = cv_scores.mean()\n",
    "    print (f\"Mean cross validation accuracy = {average_cv_score}\")\n",
    "    accuracy_drop_log[feature_name] = best_model_valid_accuracy-average_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "827a06a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are ranked from best to worst (based on how removing them impacts the accuracy of grad_boost)\n",
      "**************************************\n",
      "Feature 1.123, drop in acc 0.015249266862170097\n",
      "Feature 2.199, drop in acc 0.015249266862170097\n",
      "Feature 3.71, drop in acc 0.014076246334310816\n",
      "Feature 4.143, drop in acc 0.014076246334310816\n",
      "Feature 5.177, drop in acc 0.014076246334310816\n",
      "Feature 6.198, drop in acc 0.014076246334310816\n",
      "Feature 7.124, drop in acc 0.013489736070381175\n",
      "Feature 8.178, drop in acc 0.013489736070381175\n",
      "Feature 9.196, drop in acc 0.013489736070381175\n",
      "Feature 10.54, drop in acc 0.012903225806451535\n",
      "Feature 11.76, drop in acc 0.012903225806451535\n",
      "Feature 12.109, drop in acc 0.012903225806451535\n",
      "Feature 13.119, drop in acc 0.012903225806451535\n",
      "Feature 14.40, drop in acc 0.012316715542522005\n",
      "Feature 15.51, drop in acc 0.012316715542522005\n",
      "Feature 16.58, drop in acc 0.012316715542522005\n",
      "Feature 17.63, drop in acc 0.012316715542522005\n",
      "Feature 18.79, drop in acc 0.012316715542522005\n",
      "Feature 19.179, drop in acc 0.012316715542522005\n",
      "Feature 20.23, drop in acc 0.011730205278592365\n",
      "Feature 21.29, drop in acc 0.011730205278592365\n",
      "Feature 22.36, drop in acc 0.011730205278592365\n",
      "Feature 23.39, drop in acc 0.011730205278592365\n",
      "Feature 24.125, drop in acc 0.011730205278592365\n",
      "Feature 25.161, drop in acc 0.011730205278592365\n",
      "Feature 26.172, drop in acc 0.011730205278592365\n",
      "Feature 27.200, drop in acc 0.011730205278592365\n",
      "Feature 28.Wind Speed Daily AVG, drop in acc 0.011143695014662724\n",
      "Feature 29.4, drop in acc 0.011143695014662724\n",
      "Feature 30.10, drop in acc 0.011143695014662724\n",
      "Feature 31.21, drop in acc 0.011143695014662724\n",
      "Feature 32.22, drop in acc 0.011143695014662724\n",
      "Feature 33.26, drop in acc 0.011143695014662724\n",
      "Feature 34.28, drop in acc 0.011143695014662724\n",
      "Feature 35.34, drop in acc 0.011143695014662724\n",
      "Feature 36.41, drop in acc 0.011143695014662724\n",
      "Feature 37.52, drop in acc 0.011143695014662724\n",
      "Feature 38.61, drop in acc 0.011143695014662724\n",
      "Feature 39.67, drop in acc 0.011143695014662724\n",
      "Feature 40.82, drop in acc 0.011143695014662724\n",
      "Feature 41.86, drop in acc 0.011143695014662724\n",
      "Feature 42.96, drop in acc 0.011143695014662724\n",
      "Feature 43.117, drop in acc 0.011143695014662724\n",
      "Feature 44.140, drop in acc 0.011143695014662724\n",
      "Feature 45.159, drop in acc 0.011143695014662724\n",
      "Feature 46.166, drop in acc 0.011143695014662724\n",
      "Feature 47.171, drop in acc 0.011143695014662724\n",
      "Feature 48.174, drop in acc 0.011143695014662724\n",
      "Feature 49.176, drop in acc 0.011143695014662724\n",
      "Feature 50.189, drop in acc 0.011143695014662724\n",
      "Feature 51.Battery Voltage AVG, drop in acc 0.010557184750733084\n",
      "Feature 52.Relative Humidity AVG, drop in acc 0.010557184750733084\n",
      "Feature 53.Wind Direction AVG, drop in acc 0.010557184750733084\n",
      "Feature 54.0, drop in acc 0.010557184750733084\n",
      "Feature 55.1, drop in acc 0.010557184750733084\n",
      "Feature 56.2, drop in acc 0.010557184750733084\n",
      "Feature 57.5, drop in acc 0.010557184750733084\n",
      "Feature 58.6, drop in acc 0.010557184750733084\n",
      "Feature 59.7, drop in acc 0.010557184750733084\n",
      "Feature 60.12, drop in acc 0.010557184750733084\n",
      "Feature 61.14, drop in acc 0.010557184750733084\n",
      "Feature 62.15, drop in acc 0.010557184750733084\n",
      "Feature 63.17, drop in acc 0.010557184750733084\n",
      "Feature 64.20, drop in acc 0.010557184750733084\n",
      "Feature 65.24, drop in acc 0.010557184750733084\n",
      "Feature 66.27, drop in acc 0.010557184750733084\n",
      "Feature 67.30, drop in acc 0.010557184750733084\n",
      "Feature 68.32, drop in acc 0.010557184750733084\n",
      "Feature 69.33, drop in acc 0.010557184750733084\n",
      "Feature 70.38, drop in acc 0.010557184750733084\n",
      "Feature 71.44, drop in acc 0.010557184750733084\n",
      "Feature 72.47, drop in acc 0.010557184750733084\n",
      "Feature 73.66, drop in acc 0.010557184750733084\n",
      "Feature 74.70, drop in acc 0.010557184750733084\n",
      "Feature 75.75, drop in acc 0.010557184750733084\n",
      "Feature 76.80, drop in acc 0.010557184750733084\n",
      "Feature 77.81, drop in acc 0.010557184750733084\n",
      "Feature 78.83, drop in acc 0.010557184750733084\n",
      "Feature 79.84, drop in acc 0.010557184750733084\n",
      "Feature 80.91, drop in acc 0.010557184750733084\n",
      "Feature 81.100, drop in acc 0.010557184750733084\n",
      "Feature 82.106, drop in acc 0.010557184750733084\n",
      "Feature 83.110, drop in acc 0.010557184750733084\n",
      "Feature 84.111, drop in acc 0.010557184750733084\n",
      "Feature 85.112, drop in acc 0.010557184750733084\n",
      "Feature 86.122, drop in acc 0.010557184750733084\n",
      "Feature 87.135, drop in acc 0.010557184750733084\n",
      "Feature 88.151, drop in acc 0.010557184750733084\n",
      "Feature 89.153, drop in acc 0.010557184750733084\n",
      "Feature 90.154, drop in acc 0.010557184750733084\n",
      "Feature 91.155, drop in acc 0.010557184750733084\n",
      "Feature 92.157, drop in acc 0.010557184750733084\n",
      "Feature 93.162, drop in acc 0.010557184750733084\n",
      "Feature 94.168, drop in acc 0.010557184750733084\n",
      "Feature 95.173, drop in acc 0.010557184750733084\n",
      "Feature 96.175, drop in acc 0.010557184750733084\n",
      "Feature 97.181, drop in acc 0.010557184750733084\n",
      "Feature 98.182, drop in acc 0.010557184750733084\n",
      "Feature 99.184, drop in acc 0.010557184750733084\n",
      "Feature 100.187, drop in acc 0.010557184750733084\n",
      "Feature 101.190, drop in acc 0.010557184750733084\n",
      "Feature 102.193, drop in acc 0.010557184750733084\n",
      "Feature 103.195, drop in acc 0.010557184750733084\n",
      "Feature 104.197, drop in acc 0.010557184750733084\n",
      "Feature 105.202, drop in acc 0.010557184750733084\n",
      "Feature 106.Temperature AVG, drop in acc 0.009970674486803444\n",
      "Feature 107.3, drop in acc 0.009970674486803444\n",
      "Feature 108.9, drop in acc 0.009970674486803444\n",
      "Feature 109.13, drop in acc 0.009970674486803444\n",
      "Feature 110.16, drop in acc 0.009970674486803444\n",
      "Feature 111.18, drop in acc 0.009970674486803444\n",
      "Feature 112.25, drop in acc 0.009970674486803444\n",
      "Feature 113.31, drop in acc 0.009970674486803444\n",
      "Feature 114.35, drop in acc 0.009970674486803444\n",
      "Feature 115.37, drop in acc 0.009970674486803444\n",
      "Feature 116.42, drop in acc 0.009970674486803444\n",
      "Feature 117.43, drop in acc 0.009970674486803444\n",
      "Feature 118.45, drop in acc 0.009970674486803444\n",
      "Feature 119.46, drop in acc 0.009970674486803444\n",
      "Feature 120.48, drop in acc 0.009970674486803444\n",
      "Feature 121.57, drop in acc 0.009970674486803444\n",
      "Feature 122.60, drop in acc 0.009970674486803444\n",
      "Feature 123.68, drop in acc 0.009970674486803444\n",
      "Feature 124.72, drop in acc 0.009970674486803444\n",
      "Feature 125.77, drop in acc 0.009970674486803444\n",
      "Feature 126.85, drop in acc 0.009970674486803444\n",
      "Feature 127.88, drop in acc 0.009970674486803444\n",
      "Feature 128.92, drop in acc 0.009970674486803444\n",
      "Feature 129.118, drop in acc 0.009970674486803444\n",
      "Feature 130.126, drop in acc 0.009970674486803444\n",
      "Feature 131.156, drop in acc 0.009970674486803444\n",
      "Feature 132.164, drop in acc 0.009970674486803444\n",
      "Feature 133.167, drop in acc 0.009970674486803444\n",
      "Feature 134.169, drop in acc 0.009970674486803444\n",
      "Feature 135.170, drop in acc 0.009970674486803444\n",
      "Feature 136.183, drop in acc 0.009970674486803444\n",
      "Feature 137.185, drop in acc 0.009970674486803444\n",
      "Feature 138.188, drop in acc 0.009970674486803444\n",
      "Feature 139.192, drop in acc 0.009970674486803444\n",
      "Feature 140.194, drop in acc 0.009970674486803444\n",
      "Feature 141.203, drop in acc 0.009970674486803444\n",
      "Feature 142.Solare Radiation AVG, drop in acc 0.009384164222873914\n",
      "Feature 143.11, drop in acc 0.009384164222873914\n",
      "Feature 144.50, drop in acc 0.009384164222873914\n",
      "Feature 145.53, drop in acc 0.009384164222873914\n",
      "Feature 146.56, drop in acc 0.009384164222873914\n",
      "Feature 147.62, drop in acc 0.009384164222873914\n",
      "Feature 148.65, drop in acc 0.009384164222873914\n",
      "Feature 149.73, drop in acc 0.009384164222873914\n",
      "Feature 150.74, drop in acc 0.009384164222873914\n",
      "Feature 151.78, drop in acc 0.009384164222873914\n",
      "Feature 152.89, drop in acc 0.009384164222873914\n",
      "Feature 153.94, drop in acc 0.009384164222873914\n",
      "Feature 154.98, drop in acc 0.009384164222873914\n",
      "Feature 155.102, drop in acc 0.009384164222873914\n",
      "Feature 156.105, drop in acc 0.009384164222873914\n",
      "Feature 157.107, drop in acc 0.009384164222873914\n",
      "Feature 158.108, drop in acc 0.009384164222873914\n",
      "Feature 159.113, drop in acc 0.009384164222873914\n",
      "Feature 160.114, drop in acc 0.009384164222873914\n",
      "Feature 161.115, drop in acc 0.009384164222873914\n",
      "Feature 162.116, drop in acc 0.009384164222873914\n",
      "Feature 163.120, drop in acc 0.009384164222873914\n",
      "Feature 164.121, drop in acc 0.009384164222873914\n",
      "Feature 165.128, drop in acc 0.009384164222873914\n",
      "Feature 166.129, drop in acc 0.009384164222873914\n",
      "Feature 167.132, drop in acc 0.009384164222873914\n",
      "Feature 168.133, drop in acc 0.009384164222873914\n",
      "Feature 169.134, drop in acc 0.009384164222873914\n",
      "Feature 170.137, drop in acc 0.009384164222873914\n",
      "Feature 171.139, drop in acc 0.009384164222873914\n",
      "Feature 172.144, drop in acc 0.009384164222873914\n",
      "Feature 173.145, drop in acc 0.009384164222873914\n",
      "Feature 174.146, drop in acc 0.009384164222873914\n",
      "Feature 175.147, drop in acc 0.009384164222873914\n",
      "Feature 176.152, drop in acc 0.009384164222873914\n",
      "Feature 177.158, drop in acc 0.009384164222873914\n",
      "Feature 178.163, drop in acc 0.009384164222873914\n",
      "Feature 179.180, drop in acc 0.009384164222873914\n",
      "Feature 180.186, drop in acc 0.009384164222873914\n",
      "Feature 181.191, drop in acc 0.009384164222873914\n",
      "Feature 182.8, drop in acc 0.008797653958944274\n",
      "Feature 183.19, drop in acc 0.008797653958944274\n",
      "Feature 184.59, drop in acc 0.008797653958944274\n",
      "Feature 185.87, drop in acc 0.008797653958944274\n",
      "Feature 186.97, drop in acc 0.008797653958944274\n",
      "Feature 187.99, drop in acc 0.008797653958944274\n",
      "Feature 188.101, drop in acc 0.008797653958944274\n",
      "Feature 189.103, drop in acc 0.008797653958944274\n",
      "Feature 190.104, drop in acc 0.008797653958944274\n",
      "Feature 191.127, drop in acc 0.008797653958944274\n",
      "Feature 192.130, drop in acc 0.008797653958944274\n",
      "Feature 193.131, drop in acc 0.008797653958944274\n",
      "Feature 194.136, drop in acc 0.008797653958944274\n",
      "Feature 195.148, drop in acc 0.008797653958944274\n",
      "Feature 196.93, drop in acc 0.008211143695014633\n",
      "Feature 197.95, drop in acc 0.008211143695014633\n",
      "Feature 198.201, drop in acc 0.008211143695014633\n",
      "Feature 199.49, drop in acc 0.007624633431084993\n",
      "Feature 200.69, drop in acc 0.007624633431084993\n",
      "Feature 201.138, drop in acc 0.007624633431084993\n",
      "Feature 202.150, drop in acc 0.007624633431084993\n",
      "Feature 203.165, drop in acc 0.007624633431084993\n",
      "Feature 204.141, drop in acc 0.007038123167155352\n",
      "Feature 205.142, drop in acc 0.007038123167155352\n",
      "Feature 206.149, drop in acc 0.007038123167155352\n",
      "Feature 207.160, drop in acc 0.007038123167155352\n",
      "Feature 208.55, drop in acc 0.0058651026392961825\n",
      "Feature 209.64, drop in acc 0.0058651026392961825\n",
      "Feature 210.90, drop in acc 0.0058651026392961825\n"
     ]
    }
   ],
   "source": [
    "def criteria(l):\n",
    "    return l[1]\n",
    "\n",
    "sorted_accs =  sorted(accuracy_drop_log.items(),key=criteria, reverse=True)\n",
    "\n",
    "print (f\"Features are ranked from best to worst (based on how removing them impacts the accuracy of {best_model_name})\")\n",
    "print (f\"**************************************\")\n",
    "\n",
    "i=1\n",
    "for entry in sorted_accs:\n",
    "    feature_name = entry[0]\n",
    "    acc_drop = entry[1]\n",
    "    \n",
    "    if feature_name != \"No ablation\":\n",
    "        print (f\"Feature {i}.{feature_name}, drop in acc {acc_drop}\")\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6bea98",
   "metadata": {},
   "source": [
    "### C. Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca80d1",
   "metadata": {},
   "source": [
    "Feature ablation of Gradient Boost Classifier model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec8b22a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature Battery Voltage AVG\n",
      "Mean cross validation accuracy = 0.6387096774193548\n",
      "Removing feature Temperature AVG\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature Relative Humidity AVG\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature Wind Speed Daily AVG\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature Wind Direction AVG\n",
      "Mean cross validation accuracy = 0.6451612903225806\n",
      "Removing feature Solare Radiation AVG\n",
      "Mean cross validation accuracy = 0.632258064516129\n",
      "Removing feature 0\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 1\n",
      "Mean cross validation accuracy = 0.6410557184750733\n",
      "Removing feature 2\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 3\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 4\n",
      "Mean cross validation accuracy = 0.6410557184750733\n",
      "Removing feature 5\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 6\n",
      "Mean cross validation accuracy = 0.6451612903225806\n",
      "Removing feature 7\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 8\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 9\n",
      "Mean cross validation accuracy = 0.6451612903225806\n",
      "Removing feature 10\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 11\n",
      "Mean cross validation accuracy = 0.6457478005865103\n",
      "Removing feature 12\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 13\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 14\n",
      "Mean cross validation accuracy = 0.6469208211143694\n",
      "Removing feature 15\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 16\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 17\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 18\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 19\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 20\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 21\n",
      "Mean cross validation accuracy = 0.6340175953079179\n",
      "Removing feature 0\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 1\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 2\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 3\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 4\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 5\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 6\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 7\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 8\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 9\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 10\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 11\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 12\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 13\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 14\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 15\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 16\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 17\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 18\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 19\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 20\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 21\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 22\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 23\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 24\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 25\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 26\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 27\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 28\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 29\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 30\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 31\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 32\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 33\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 34\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 35\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 36\n",
      "Mean cross validation accuracy = 0.6457478005865103\n",
      "Removing feature 37\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 38\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 39\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 40\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 41\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 42\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 43\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 44\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 45\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 46\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 47\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 48\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 49\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 50\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 51\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 52\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 53\n",
      "Mean cross validation accuracy = 0.6463343108504398\n",
      "Removing feature 54\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 55\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 56\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 57\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 58\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 59\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 60\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 61\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 62\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 63\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 64\n",
      "Mean cross validation accuracy = 0.6457478005865103\n",
      "Removing feature 65\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 66\n",
      "Mean cross validation accuracy = 0.6457478005865103\n",
      "Removing feature 67\n",
      "Mean cross validation accuracy = 0.6451612903225806\n",
      "Removing feature 68\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 69\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 70\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 71\n",
      "Mean cross validation accuracy = 0.6416422287390029\n",
      "Removing feature 72\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 73\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 74\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 75\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 76\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 77\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 78\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 79\n",
      "Mean cross validation accuracy = 0.6387096774193548\n",
      "Removing feature 80\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 81\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 82\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 83\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 84\n",
      "Mean cross validation accuracy = 0.6475073313782991\n",
      "Removing feature 85\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 86\n",
      "Mean cross validation accuracy = 0.6451612903225806\n",
      "Removing feature 87\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 88\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 89\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 90\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 91\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 92\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 93\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 94\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 95\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 96\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 97\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 98\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 99\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 100\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 101\n",
      "Mean cross validation accuracy = 0.6463343108504398\n",
      "Removing feature 102\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 103\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 104\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 105\n",
      "Mean cross validation accuracy = 0.6451612903225806\n",
      "Removing feature 106\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 107\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 108\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 109\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 110\n",
      "Mean cross validation accuracy = 0.6416422287390029\n",
      "Removing feature 111\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 112\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 113\n",
      "Mean cross validation accuracy = 0.6451612903225806\n",
      "Removing feature 114\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 115\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 116\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 117\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 118\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 119\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 120\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 121\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 122\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 123\n",
      "Mean cross validation accuracy = 0.6480938416422287\n",
      "Removing feature 124\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 125\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 126\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 127\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 128\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 129\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 130\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 131\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 132\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 133\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 134\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 135\n",
      "Mean cross validation accuracy = 0.6451612903225806\n",
      "Removing feature 136\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 137\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 138\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 139\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 140\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 141\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 142\n",
      "Mean cross validation accuracy = 0.6463343108504398\n",
      "Removing feature 143\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 144\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 145\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 146\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 147\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 148\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 149\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 150\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 151\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 152\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 153\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 154\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 155\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 156\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 157\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 158\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 159\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 160\n",
      "Mean cross validation accuracy = 0.6457478005865103\n",
      "Removing feature 161\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 162\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 163\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 164\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 165\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 166\n",
      "Mean cross validation accuracy = 0.6451612903225806\n",
      "Removing feature 167\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 168\n",
      "Mean cross validation accuracy = 0.6451612903225806\n",
      "Removing feature 169\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 170\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 171\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 172\n",
      "Mean cross validation accuracy = 0.6451612903225806\n",
      "Removing feature 173\n",
      "Mean cross validation accuracy = 0.6457478005865103\n",
      "Removing feature 174\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 175\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 176\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 177\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 178\n",
      "Mean cross validation accuracy = 0.6457478005865103\n",
      "Removing feature 179\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 180\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 181\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 182\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 183\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 184\n",
      "Mean cross validation accuracy = 0.6422287390029325\n",
      "Removing feature 185\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 186\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 187\n",
      "Mean cross validation accuracy = 0.6457478005865103\n",
      "Removing feature 188\n",
      "Mean cross validation accuracy = 0.6451612903225806\n",
      "Removing feature 189\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 190\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 191\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 192\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 193\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 194\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 195\n",
      "Mean cross validation accuracy = 0.6434017595307917\n",
      "Removing feature 196\n",
      "Mean cross validation accuracy = 0.6428152492668622\n",
      "Removing feature 197\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 198\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 199\n",
      "Mean cross validation accuracy = 0.6439882697947213\n",
      "Removing feature 200\n",
      "Mean cross validation accuracy = 0.6451612903225806\n",
      "Removing feature 201\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 202\n",
      "Mean cross validation accuracy = 0.644574780058651\n",
      "Removing feature 203\n",
      "Mean cross validation accuracy = 0.6439882697947213\n"
     ]
    }
   ],
   "source": [
    "best_model = GradientBoostingClassifier()\n",
    "\n",
    "feature_names = ranier_features_df.columns\n",
    "\n",
    "# Maintain an accuracy dictionary\n",
    "\n",
    "accuracy_drop_log = {\"No ablation\":0}\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    # Drop one feature at a time\n",
    "    feature_name = feature_names[i]\n",
    "    print (f\"Removing feature {feature_name}\")\n",
    "    \n",
    "    # Remove the feature by not selecting the column from the index i\n",
    "\n",
    "    x_ablated = numpy.delete(_x,i,axis=1) # axis = 1 means columns\n",
    "    \n",
    "    cv_scores = cross_val_score(best_model,x_ablated,_y.flatten(), cv=k, n_jobs=4)\n",
    "    average_cv_score = cv_scores.mean()\n",
    "    print (f\"Mean cross validation accuracy = {average_cv_score}\")\n",
    "    accuracy_drop_log[feature_name] = best_model_valid_accuracy-average_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc1187e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are ranked from best to worst (based on how removing them impacts the accuracy of grad_boost)\n",
      "**************************************\n",
      "Feature 1.Solare Radiation AVG, drop in acc 0.011730205278592365\n",
      "Feature 2.Battery Voltage AVG, drop in acc 0.005278592375366542\n",
      "Feature 3.79, drop in acc 0.005278592375366542\n",
      "Feature 4.71, drop in acc 0.002346041055718451\n",
      "Feature 5.110, drop in acc 0.002346041055718451\n",
      "Feature 6.20, drop in acc 0.0017595307917888103\n",
      "Feature 7.47, drop in acc 0.0017595307917888103\n",
      "Feature 8.51, drop in acc 0.0017595307917888103\n",
      "Feature 9.57, drop in acc 0.0017595307917888103\n",
      "Feature 10.68, drop in acc 0.0017595307917888103\n",
      "Feature 11.72, drop in acc 0.0017595307917888103\n",
      "Feature 12.83, drop in acc 0.0017595307917888103\n",
      "Feature 13.88, drop in acc 0.0017595307917888103\n",
      "Feature 14.128, drop in acc 0.0017595307917888103\n",
      "Feature 15.130, drop in acc 0.0017595307917888103\n",
      "Feature 16.131, drop in acc 0.0017595307917888103\n",
      "Feature 17.139, drop in acc 0.0017595307917888103\n",
      "Feature 18.141, drop in acc 0.0017595307917888103\n",
      "Feature 19.149, drop in acc 0.0017595307917888103\n",
      "Feature 20.158, drop in acc 0.0017595307917888103\n",
      "Feature 21.163, drop in acc 0.0017595307917888103\n",
      "Feature 22.170, drop in acc 0.0017595307917888103\n",
      "Feature 23.171, drop in acc 0.0017595307917888103\n",
      "Feature 24.179, drop in acc 0.0017595307917888103\n",
      "Feature 25.181, drop in acc 0.0017595307917888103\n",
      "Feature 26.184, drop in acc 0.0017595307917888103\n",
      "Feature 27.6, drop in acc 0.0011730205278591699\n",
      "Feature 28.17, drop in acc 0.0011730205278591699\n",
      "Feature 29.26, drop in acc 0.0011730205278591699\n",
      "Feature 30.35, drop in acc 0.0011730205278591699\n",
      "Feature 31.37, drop in acc 0.0011730205278591699\n",
      "Feature 32.40, drop in acc 0.0011730205278591699\n",
      "Feature 33.42, drop in acc 0.0011730205278591699\n",
      "Feature 34.43, drop in acc 0.0011730205278591699\n",
      "Feature 35.48, drop in acc 0.0011730205278591699\n",
      "Feature 36.50, drop in acc 0.0011730205278591699\n",
      "Feature 37.56, drop in acc 0.0011730205278591699\n",
      "Feature 38.63, drop in acc 0.0011730205278591699\n",
      "Feature 39.73, drop in acc 0.0011730205278591699\n",
      "Feature 40.78, drop in acc 0.0011730205278591699\n",
      "Feature 41.87, drop in acc 0.0011730205278591699\n",
      "Feature 42.94, drop in acc 0.0011730205278591699\n",
      "Feature 43.97, drop in acc 0.0011730205278591699\n",
      "Feature 44.98, drop in acc 0.0011730205278591699\n",
      "Feature 45.99, drop in acc 0.0011730205278591699\n",
      "Feature 46.102, drop in acc 0.0011730205278591699\n",
      "Feature 47.118, drop in acc 0.0011730205278591699\n",
      "Feature 48.119, drop in acc 0.0011730205278591699\n",
      "Feature 49.127, drop in acc 0.0011730205278591699\n",
      "Feature 50.137, drop in acc 0.0011730205278591699\n",
      "Feature 51.150, drop in acc 0.0011730205278591699\n",
      "Feature 52.152, drop in acc 0.0011730205278591699\n",
      "Feature 53.156, drop in acc 0.0011730205278591699\n",
      "Feature 54.180, drop in acc 0.0011730205278591699\n",
      "Feature 55.182, drop in acc 0.0011730205278591699\n",
      "Feature 56.185, drop in acc 0.0011730205278591699\n",
      "Feature 57.189, drop in acc 0.0011730205278591699\n",
      "Feature 58.193, drop in acc 0.0011730205278591699\n",
      "Feature 59.196, drop in acc 0.0011730205278591699\n",
      "Feature 60.0, drop in acc 0.0005865102639296405\n",
      "Feature 61.1, drop in acc 0.0005865102639296405\n",
      "Feature 62.4, drop in acc 0.0005865102639296405\n",
      "Feature 63.5, drop in acc 0.0005865102639296405\n",
      "Feature 64.8, drop in acc 0.0005865102639296405\n",
      "Feature 65.13, drop in acc 0.0005865102639296405\n",
      "Feature 66.14, drop in acc 0.0005865102639296405\n",
      "Feature 67.16, drop in acc 0.0005865102639296405\n",
      "Feature 68.19, drop in acc 0.0005865102639296405\n",
      "Feature 69.21, drop in acc 0.0005865102639296405\n",
      "Feature 70.23, drop in acc 0.0005865102639296405\n",
      "Feature 71.25, drop in acc 0.0005865102639296405\n",
      "Feature 72.27, drop in acc 0.0005865102639296405\n",
      "Feature 73.31, drop in acc 0.0005865102639296405\n",
      "Feature 74.34, drop in acc 0.0005865102639296405\n",
      "Feature 75.38, drop in acc 0.0005865102639296405\n",
      "Feature 76.41, drop in acc 0.0005865102639296405\n",
      "Feature 77.45, drop in acc 0.0005865102639296405\n",
      "Feature 78.46, drop in acc 0.0005865102639296405\n",
      "Feature 79.55, drop in acc 0.0005865102639296405\n",
      "Feature 80.59, drop in acc 0.0005865102639296405\n",
      "Feature 81.60, drop in acc 0.0005865102639296405\n",
      "Feature 82.61, drop in acc 0.0005865102639296405\n",
      "Feature 83.62, drop in acc 0.0005865102639296405\n",
      "Feature 84.69, drop in acc 0.0005865102639296405\n",
      "Feature 85.80, drop in acc 0.0005865102639296405\n",
      "Feature 86.89, drop in acc 0.0005865102639296405\n",
      "Feature 87.95, drop in acc 0.0005865102639296405\n",
      "Feature 88.100, drop in acc 0.0005865102639296405\n",
      "Feature 89.104, drop in acc 0.0005865102639296405\n",
      "Feature 90.106, drop in acc 0.0005865102639296405\n",
      "Feature 91.107, drop in acc 0.0005865102639296405\n",
      "Feature 92.109, drop in acc 0.0005865102639296405\n",
      "Feature 93.111, drop in acc 0.0005865102639296405\n",
      "Feature 94.112, drop in acc 0.0005865102639296405\n",
      "Feature 95.114, drop in acc 0.0005865102639296405\n",
      "Feature 96.116, drop in acc 0.0005865102639296405\n",
      "Feature 97.124, drop in acc 0.0005865102639296405\n",
      "Feature 98.129, drop in acc 0.0005865102639296405\n",
      "Feature 99.133, drop in acc 0.0005865102639296405\n",
      "Feature 100.134, drop in acc 0.0005865102639296405\n",
      "Feature 101.138, drop in acc 0.0005865102639296405\n",
      "Feature 102.143, drop in acc 0.0005865102639296405\n",
      "Feature 103.147, drop in acc 0.0005865102639296405\n",
      "Feature 104.148, drop in acc 0.0005865102639296405\n",
      "Feature 105.154, drop in acc 0.0005865102639296405\n",
      "Feature 106.159, drop in acc 0.0005865102639296405\n",
      "Feature 107.165, drop in acc 0.0005865102639296405\n",
      "Feature 108.169, drop in acc 0.0005865102639296405\n",
      "Feature 109.174, drop in acc 0.0005865102639296405\n",
      "Feature 110.175, drop in acc 0.0005865102639296405\n",
      "Feature 111.176, drop in acc 0.0005865102639296405\n",
      "Feature 112.195, drop in acc 0.0005865102639296405\n",
      "Feature 113.Temperature AVG, drop in acc 0.0\n",
      "Feature 114.Relative Humidity AVG, drop in acc 0.0\n",
      "Feature 115.2, drop in acc 0.0\n",
      "Feature 116.7, drop in acc 0.0\n",
      "Feature 117.10, drop in acc 0.0\n",
      "Feature 118.11, drop in acc 0.0\n",
      "Feature 119.12, drop in acc 0.0\n",
      "Feature 120.15, drop in acc 0.0\n",
      "Feature 121.18, drop in acc 0.0\n",
      "Feature 122.22, drop in acc 0.0\n",
      "Feature 123.24, drop in acc 0.0\n",
      "Feature 124.28, drop in acc 0.0\n",
      "Feature 125.29, drop in acc 0.0\n",
      "Feature 126.30, drop in acc 0.0\n",
      "Feature 127.32, drop in acc 0.0\n",
      "Feature 128.39, drop in acc 0.0\n",
      "Feature 129.44, drop in acc 0.0\n",
      "Feature 130.49, drop in acc 0.0\n",
      "Feature 131.52, drop in acc 0.0\n",
      "Feature 132.58, drop in acc 0.0\n",
      "Feature 133.65, drop in acc 0.0\n",
      "Feature 134.70, drop in acc 0.0\n",
      "Feature 135.74, drop in acc 0.0\n",
      "Feature 136.75, drop in acc 0.0\n",
      "Feature 137.77, drop in acc 0.0\n",
      "Feature 138.81, drop in acc 0.0\n",
      "Feature 139.82, drop in acc 0.0\n",
      "Feature 140.85, drop in acc 0.0\n",
      "Feature 141.90, drop in acc 0.0\n",
      "Feature 142.92, drop in acc 0.0\n",
      "Feature 143.93, drop in acc 0.0\n",
      "Feature 144.96, drop in acc 0.0\n",
      "Feature 145.117, drop in acc 0.0\n",
      "Feature 146.121, drop in acc 0.0\n",
      "Feature 147.125, drop in acc 0.0\n",
      "Feature 148.126, drop in acc 0.0\n",
      "Feature 149.140, drop in acc 0.0\n",
      "Feature 150.144, drop in acc 0.0\n",
      "Feature 151.145, drop in acc 0.0\n",
      "Feature 152.151, drop in acc 0.0\n",
      "Feature 153.153, drop in acc 0.0\n",
      "Feature 154.155, drop in acc 0.0\n",
      "Feature 155.157, drop in acc 0.0\n",
      "Feature 156.161, drop in acc 0.0\n",
      "Feature 157.162, drop in acc 0.0\n",
      "Feature 158.183, drop in acc 0.0\n",
      "Feature 159.190, drop in acc 0.0\n",
      "Feature 160.194, drop in acc 0.0\n",
      "Feature 161.197, drop in acc 0.0\n",
      "Feature 162.198, drop in acc 0.0\n",
      "Feature 163.199, drop in acc 0.0\n",
      "Feature 164.203, drop in acc 0.0\n",
      "Feature 165.Wind Speed Daily AVG, drop in acc -0.0005865102639296405\n",
      "Feature 166.3, drop in acc -0.0005865102639296405\n",
      "Feature 167.9, drop in acc -0.0005865102639296405\n",
      "Feature 168.33, drop in acc -0.0005865102639296405\n",
      "Feature 169.54, drop in acc -0.0005865102639296405\n",
      "Feature 170.76, drop in acc -0.0005865102639296405\n",
      "Feature 171.91, drop in acc -0.0005865102639296405\n",
      "Feature 172.103, drop in acc -0.0005865102639296405\n",
      "Feature 173.108, drop in acc -0.0005865102639296405\n",
      "Feature 174.115, drop in acc -0.0005865102639296405\n",
      "Feature 175.120, drop in acc -0.0005865102639296405\n",
      "Feature 176.122, drop in acc -0.0005865102639296405\n",
      "Feature 177.132, drop in acc -0.0005865102639296405\n",
      "Feature 178.136, drop in acc -0.0005865102639296405\n",
      "Feature 179.146, drop in acc -0.0005865102639296405\n",
      "Feature 180.164, drop in acc -0.0005865102639296405\n",
      "Feature 181.167, drop in acc -0.0005865102639296405\n",
      "Feature 182.177, drop in acc -0.0005865102639296405\n",
      "Feature 183.186, drop in acc -0.0005865102639296405\n",
      "Feature 184.191, drop in acc -0.0005865102639296405\n",
      "Feature 185.192, drop in acc -0.0005865102639296405\n",
      "Feature 186.201, drop in acc -0.0005865102639296405\n",
      "Feature 187.202, drop in acc -0.0005865102639296405\n",
      "Feature 188.Wind Direction AVG, drop in acc -0.001173020527859281\n",
      "Feature 189.67, drop in acc -0.001173020527859281\n",
      "Feature 190.86, drop in acc -0.001173020527859281\n",
      "Feature 191.105, drop in acc -0.001173020527859281\n",
      "Feature 192.113, drop in acc -0.001173020527859281\n",
      "Feature 193.135, drop in acc -0.001173020527859281\n",
      "Feature 194.166, drop in acc -0.001173020527859281\n",
      "Feature 195.168, drop in acc -0.001173020527859281\n",
      "Feature 196.172, drop in acc -0.001173020527859281\n",
      "Feature 197.188, drop in acc -0.001173020527859281\n",
      "Feature 198.200, drop in acc -0.001173020527859281\n",
      "Feature 199.36, drop in acc -0.0017595307917889214\n",
      "Feature 200.64, drop in acc -0.0017595307917889214\n",
      "Feature 201.66, drop in acc -0.0017595307917889214\n",
      "Feature 202.160, drop in acc -0.0017595307917889214\n",
      "Feature 203.173, drop in acc -0.0017595307917889214\n",
      "Feature 204.178, drop in acc -0.0017595307917889214\n",
      "Feature 205.187, drop in acc -0.0017595307917889214\n",
      "Feature 206.53, drop in acc -0.002346041055718451\n",
      "Feature 207.101, drop in acc -0.002346041055718451\n",
      "Feature 208.142, drop in acc -0.002346041055718451\n",
      "Feature 209.84, drop in acc -0.0035190615835777317\n",
      "Feature 210.123, drop in acc -0.004105571847507372\n"
     ]
    }
   ],
   "source": [
    "def criteria(l):\n",
    "    return l[1]\n",
    "\n",
    "sorted_accs =  sorted(accuracy_drop_log.items(),key=criteria, reverse=True)\n",
    "\n",
    "print (f\"Features are ranked from best to worst (based on how removing them impacts the accuracy of {best_model_name})\")\n",
    "print (f\"**************************************\")\n",
    "\n",
    "i=1\n",
    "for entry in sorted_accs:\n",
    "    feature_name = entry[0]\n",
    "    acc_drop = entry[1]\n",
    "    \n",
    "    if feature_name != \"No ablation\":\n",
    "        print (f\"Feature {i}.{feature_name}, drop in acc {acc_drop}\")\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016eaffe",
   "metadata": {},
   "source": [
    "# Comments, Insights, and Result Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f7863",
   "metadata": {},
   "source": [
    "The ability to predict hiking rates can determine a hikers success, safety, and overall happiness. In order to predict if the user should hike or not I utilized three model candidates - Logisitic Regression, SVC, and Gradient Boosting Classifier. Each model returned a very similar validation score. The best model for the task is grad_boost which offers the validation accuracy of 0.6416422287390029. Whereas Logisitc Regression and SVC both received an accuracy score of 0.626. \n",
    "\n",
    "The top five features for each model. \n",
    "\n",
    "Linear Regression\n",
    "Feature 1.173, drop in acc 0.02580645161290318\n",
    "Feature 2.191, drop in acc 0.02346041055718473\n",
    "Feature 3.43, drop in acc 0.02287390029325509\n",
    "Feature 4.56, drop in acc 0.02228739002932545\n",
    "Feature 5.53, drop in acc 0.02170087976539581\n",
    "\n",
    "SVC\n",
    "Feature 1.123, drop in acc 0.015249266862170097\n",
    "Feature 2.199, drop in acc 0.015249266862170097\n",
    "Feature 3.71, drop in acc 0.014076246334310816\n",
    "Feature 4.143, drop in acc 0.014076246334310816\n",
    "Feature 5.177, drop in acc 0.014076246334310816\n",
    "\n",
    "Gradient \n",
    "Feature 1.Solare Radiation AVG, drop in acc 0.011730205278592365\n",
    "Feature 2.Battery Voltage AVG, drop in acc 0.005278592375366542\n",
    "Feature 3.79, drop in acc 0.005278592375366542\n",
    "Feature 4.71, drop in acc 0.002346041055718451\n",
    "Feature 5.110, drop in acc 0.002346041055718451\n",
    "\n",
    "Because the variables \"Route\" and \"Date\" were transformed into numerical data points they appear as individual values. \"Route\" was coded as 0-21 and \"Date\" was coded as 22-203. Therefore, an interpretation of the values listed below would appear like this. \n",
    "\n",
    "Linear Regression\n",
    "\"Date\", drop in acc 0.02580645161290318\n",
    "\"Date\", drop in acc 0.02346041055718473\n",
    "\"Date\", drop in acc 0.02287390029325509\n",
    "\"Date\", drop in acc 0.02228739002932545\n",
    "\"Date\", drop in acc 0.02170087976539581\n",
    "\n",
    "SVC\n",
    "\"Date\", drop in acc 0.015249266862170097\n",
    "\"Date\", drop in acc 0.015249266862170097\n",
    "\"Date\", drop in acc 0.014076246334310816\n",
    "\"Date\", drop in acc 0.014076246334310816\n",
    "\"Date\", drop in acc 0.014076246334310816\n",
    "\n",
    "Gradient \n",
    "Feature 1.Solare Radiation AVG, drop in acc 0.011730205278592365\n",
    "Feature 2.Battery Voltage AVG, drop in acc 0.005278592375366542\n",
    "\"Date\", drop in acc 0.005278592375366542\n",
    "\"Date\", drop in acc 0.002346041055718451\n",
    "\"Date\", drop in acc 0.002346041055718451\n",
    "\n",
    "Based on the rankings of each three models it can be concluded that removing the feature \"date\" would improve the accuracy of each model. Date is highly variable year to year, ecspecially when it is recorded on a day/month/year basis. Shortening the Date down to month and date would also leave less room for variance within the data. As, while the hiking success can vary on a dod, yoy basis, weather trends are more likely to be consistent month to month. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
